{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Тестовое_задание.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DBcreator/Test-task/blob/main/%D0%A2%D0%B5%D1%81%D1%82%D0%BE%D0%B2%D0%BE%D0%B5_%D0%B7%D0%B0%D0%B4%D0%B0%D0%BD%D0%B8%D0%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USRXLIXrbaAX"
      },
      "source": [
        "В этой задаче вам предлагается научиться по заголовку искать статью в некотором заданном множестве."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RywJ11m-TerR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f20c02a3-e0e6-4f6a-8922-8b9295715b2e"
      },
      "source": [
        "!pip install corus \n",
        "!wget https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: corus in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "--2021-04-10 20:05:09--  https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/87156914/0b363e00-0126-11e9-9e3c-e8c235463bd6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210410%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210410T200509Z&X-Amz-Expires=300&X-Amz-Signature=90ad66e323fd24469d0e86b37e2b312b9a2c9d77e888a5c8f031cacca3c9f504&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=87156914&response-content-disposition=attachment%3B%20filename%3Dlenta-ru-news.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-04-10 20:05:09--  https://github-releases.githubusercontent.com/87156914/0b363e00-0126-11e9-9e3c-e8c235463bd6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210410%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210410T200509Z&X-Amz-Expires=300&X-Amz-Signature=90ad66e323fd24469d0e86b37e2b312b9a2c9d77e888a5c8f031cacca3c9f504&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=87156914&response-content-disposition=attachment%3B%20filename%3Dlenta-ru-news.csv.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.110.154, 185.199.111.154, 185.199.108.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.110.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 527373240 (503M) [application/octet-stream]\n",
            "Saving to: ‘lenta-ru-news.csv.gz.6’\n",
            "\n",
            "lenta-ru-news.csv.g 100%[===================>] 502.94M  95.4MB/s    in 5.2s    \n",
            "\n",
            "2021-04-10 20:05:15 (97.1 MB/s) - ‘lenta-ru-news.csv.gz.6’ saved [527373240/527373240]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pdphv-sN8Qa",
        "outputId": "d3c1ddbc-714c-416c-aa04-f385f0b706f7"
      },
      "source": [
        "'''\n",
        "Для решения данной задачи воспользуемся библиотекой navec с предобученными эмбеддингами для русского языка\n",
        "'''\n",
        "!pip install navec"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: navec in /usr/local/lib/python3.7/dist-packages (0.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from navec) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lq1oQ4m-TiZT"
      },
      "source": [
        "import random\n",
        "from corus import load_lenta"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_nvMmkrXULh",
        "outputId": "b910ab69-4911-4cb1-d0c0-a6b7377f6785"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "tokenizer = WordPunctTokenizer()\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PFZPONpeYNO",
        "outputId": "5f848c14-5688-4f01-ea64-c1e9d9825c52"
      },
      "source": [
        "!pip install pymorphy2"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.7/dist-packages (0.9.1)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (2.4.417127.4579844)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.7.2)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z72qfhHCeU1t"
      },
      "source": [
        "import pymorphy2\n",
        "morph = pymorphy2.MorphAnalyzer()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw43y6SyXZOb"
      },
      "source": [
        "russian_stopwords = stopwords.words(\"russian\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YngQ6EKMOKIB",
        "outputId": "58e80e1d-c9e4-4c77-a3ed-0dd95b0345cb"
      },
      "source": [
        "!wget https://storage.yandexcloud.net/natasha-navec/packs/navec_news_v1_1B_250K_300d_100q.tar"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-10 20:05:22--  https://storage.yandexcloud.net/natasha-navec/packs/navec_news_v1_1B_250K_300d_100q.tar\n",
            "Resolving storage.yandexcloud.net (storage.yandexcloud.net)... 213.180.193.243, 2a02:6b8::1d9\n",
            "Connecting to storage.yandexcloud.net (storage.yandexcloud.net)|213.180.193.243|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26634240 (25M) [application/x-tar]\n",
            "Saving to: ‘navec_news_v1_1B_250K_300d_100q.tar.2’\n",
            "\n",
            "navec_news_v1_1B_25 100%[===================>]  25.40M  11.8MB/s    in 2.2s    \n",
            "\n",
            "2021-04-10 20:05:25 (11.8 MB/s) - ‘navec_news_v1_1B_250K_300d_100q.tar.2’ saved [26634240/26634240]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yv67jW89OULu"
      },
      "source": [
        "from navec import Navec\n",
        "\n",
        "path = 'navec_news_v1_1B_250K_300d_100q.tar'\n",
        "navec = Navec.load(path)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hq6Fx1AHa8S-"
      },
      "source": [
        "Для простоты возьмём первые 10000 новостей"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJSCQ-tOTltm"
      },
      "source": [
        "path = 'lenta-ru-news.csv.gz'\n",
        "corpus = []\n",
        "requests = []\n",
        "for i, record in zip(range(10000), load_lenta(path)):\n",
        "    corpus.append((i, record.text))\n",
        "    requests.append((i, record.title))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJlLd5_GCx6W"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity, manhattan_distances, euclidean_distances\n",
        "from copy import deepcopy"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krTm1G-citWF"
      },
      "source": [
        "Теперь необходимо реализовать класс, отвечающий за поиск новостей. Возможным подходом будет выбрать какое-нибудь векторное представление текста (bag-of-words, tf-idf, word2vec и т.п.) и метрику расстояния (косинусное, Евклидово, манхэттенское и т.п.), а потом сортировать новости по расстоянию до заголовка. Однако, вы можете реализовывать любые ваши идеи."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaDjYsNgUIOo"
      },
      "source": [
        "class Database:\n",
        "    def __init__(self, corpus):\n",
        "        self.corpus = corpus\n",
        "        # Тут должна быть ваша реализация\n",
        "        self.data = [elem[1] for elem in self.corpus]\n",
        "        self.vec_text  = np.array([self.request_to_vec(self.data[i], navec)\n",
        "                        for i in range(len(self.data))])\n",
        "        \n",
        "    \n",
        "    def request_to_vec(self, request, embeddings, dimension=300):\n",
        "\n",
        "      '''\n",
        "      Данный метод векторизует request при помощи эмбеддингов\n",
        "      '''\n",
        "    \n",
        "      request = request.lower() \n",
        "      request = re.sub(r'[{}]'.format(string.punctuation), ' ', request)\n",
        "      for stop_word in russian_stopwords:\n",
        "          request = re.sub(r'\\b{}\\b'.format(stop_word), '',request)\n",
        "      request = morph.parse(request)[0].normal_form\n",
        "\n",
        "      words = tokenizer.tokenize(str(request))\n",
        "      result = np.array([0] * dimension, dtype=float)\n",
        "    \n",
        "      for word in words:\n",
        "          if word in embeddings:\n",
        "              result += embeddings[word]\n",
        "          \n",
        "      return result  \n",
        "\n",
        "    def find(self, request, k=10):\n",
        "        \"\"\"\n",
        "            Этот метод должен принимать на вход текст заголовка и возвращать\n",
        "            для него k самых вероятных новости.\n",
        "            В качестве возвращаемого значения ожидается numpy-массив размера k, \n",
        "            содержащий id новостей в порядке уменьшения релевантности\n",
        "        \"\"\"\n",
        "        # Тут должна быть ваша реализация\n",
        "        vec_request = self.request_to_vec(request, navec)\n",
        "        rank_candidates = np.array([i for i in range(len(self.vec_text))])\n",
        "\n",
        "        dist = cosine_similarity(self.vec_text, np.array([vec_request]))[:, 0]\n",
        "        id_news = deepcopy(rank_candidates[dist.argsort()[::-1]])[: k]\n",
        "\n",
        "        return id_news"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1pQCfW_b1xo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66f3e92f-d30b-4145-ff9f-51a988a6d10e"
      },
      "source": [
        "%%time\n",
        "database = Database(corpus)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 15s, sys: 268 ms, total: 1min 16s\n",
            "Wall time: 1min 16s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIQeZTtNh-7k"
      },
      "source": [
        "Проверим глазами разумность ранжирования новостей на отдельном примере "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwbkWn-aiBeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f865518-743b-4475-bc4a-6cf0f68fd568"
      },
      "source": [
        "request_id, request_text = requests[809]\n",
        "print(f'For request (id={request_id}): {request_text}')\n",
        "print('Responses are:')\n",
        "for i, response_id in enumerate(database.find(request_text)):\n",
        "    print(f'{i}    id={response_id}\\t{corpus[response_id][1]}')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For request (id=809): Названы любимые супергеройские фильмы россиян\n",
            "Responses are:\n",
            "0    id=7853\tАмериканское издание Esquire составило список из 27 лучших фильмов о порнографии и звездах этой индустрии. В перечень вошли как художественные, так и документальные ленты. Среди неигровых картин о порно кинокритики отметили «В глубокой глотке», «Жизнь после карьеры в порно», «Жизнь после карьеры в порно — 2», «Разыскиваются горячие девушки» и одноименный шестисерийный фильм-продолжение. В список игровых фильмов попали комедии «Домашнее видео» с Кэмерон Диаз и Джейсоном Сигелом, «Капитан Оргазмо» от создателя «Южного парка» Трея Паркера, «Зак и Мири снимают порно» с Элизабет Бэнкс и Сетом Рогеном и японская лента «Порнографы: Введение в антропологию» 1966 года. Также кинокритики указали такие картины, как «Старлетка», «Страсти Дон Жуана», «Народ против Ларри Флинта», «Лавлэйс», «Соседка» и «Непристойная Бетти Пейдж». В марте портал BuzzFeed составил список из 16 наиболее нелепых порнофильмов, пародирующих культовые кинокартины, сериалы и мультфильмы.\n",
            "1    id=656\tРедакторы сайта «КиноПоиск» составили список 20 лучших фильмов об истории хип-хопа. Подборка размещена на сайте Kinopoisk. Открывает киногид фильм «Дикий стиль», снятый в 1983 году, когда хип-хоп считался локальной субкультурой. В картине снялись непрофессиональные актеры, пионеры хип-хопа Fab Five, Freddy и Grandmaster Flash. «Дикий стиль» оказал серьезное влияние на последующее развитие рэпа, некоторые исполнители впоследствии использовали сэмплы из кинофильма в своем творчестве. В подборке упоминается документальный сериал «Эволюция хип-хопа», вышедший в 2016 году. В нем рассказывается о том, как рэп из маргинальной культуры эволюционировал в мейнстрим. В список включены киноработы, посвященные отдельным ярким представителям жанра. Например, картина «Голос улиц» (2015) рассказывает о группе N.W.A., фильм «Тупак: воскрешение» (2003), номинированный на премию «Оскар», — об исполнителе Тупаке. Отдельное внимание уделяется лентам о развитии рэпа в России. Например, в список была включена картина «Настоящий рэп» 2012 года и «Батл» 2018-го. Также в подборку вошли фильмы: «Бит-стрит» (1984), «Войны стиля» (1983), «Бигги и Тупак» (2002), «Атланта» (2016-2018), «Отвязные каникулы» (2012), «Блок Пати» (2005), «Биты, рифмы и жизнь: Путешествия группы A Tribe Called Quest» (2011), «Хип-хоп рогаток» (2009), «Вавилонские мечтатели» (2016), «Клан Токио» (2014), «Восьмая миля» (2008), Bodied (2018), «Алехин» (2012), «Внутренний рэп» (2016).\n",
            "2    id=5879\tИздание BBC News составило список лучших фильмов всех времен, снятых не на английском языке. В рейтинг вошли 100 картин. «В этом году мы почувствовали, что пришло время перенести фокус с Голливуда и сосредоточиться на лучшем кинематографе со всего мира», — отметили авторы. На первой строчке оказалась лента из Японии — «Семь самураев» режиссера Акиры Куросавы, снятая в 1954 году. На втором месте — «Похитители велосипедов» итальянского кинематографиста Витторио де Сики 1948 года. Замыкает тройку «Токийская история» 1953-го, созданная японцем Ясудзиро Одзу. В топ-10 также вошли фильмы «Расемон», «Правила игры», «Персона», «Восемь с половиной», «400 ударов», «Любовное настроение» и «Сладкая жизнь». В рейтинг включили шесть произведений, снятых на русском языке: «Человек с киноаппаратом», «Иди и смотри», «Сталкер», «Андрей Рублев», «Броненосец \"Потемкин\"» и «Зеркало». Автор трех из них — Андрей Тарковский. Языком-лидером по присутствию в рейтинге оказался французский — на нем сняты 27 из 100 лучших картин. При этом четверть списка составили ленты из Юго-Восточной Азии. Подборка сделана на основе опроса 209 кинокритиков из 43 стран. Составители рейтинга подчеркнули, что их разочаровало количество фильмов в списке, созданных женщинами, — из 100 лент таких только четыре — но заверили, что пытались обеспечить половое разнообразие. Так, среди опрошенных критиков, 94 были женщинами.\n",
            "3    id=5147\tРоссийский рэпер Слава КПСС совместно с рэпером Джигли записал трек «Характерные для рэперов слова». Видео опубликовано на YouTube в среду, 7 ноября. Текст песни состоит из наиболее популярных слов отечественных рэп-исполнителей. В композиции музыканты перечисляют любимые слова таких артистов, как Пика, Элджей, Скруджи, Баста. Например, первая строчка выглядит так: «Хэй, свежевыжатый, пляс, альфа, ниндзя…». Ранее стриминговый сервис «Яндекс.Музыка» провел исследование и составил карту самых популярных слов русского рэпа. Наиболее часто используемым глаголом оказалось слово «базарить». Топ прилагательных и наречий состоит в основном из ненормативной лексики.\n",
            "4    id=3981\tРоссийский короткометражный фильм «Лалай-Балалай» выложили в открытый доступ. Комедию опубликовали на Vimeo-канале Stereotactic. «Лалай-Балалай» — это 12-минутная комедия, главные герои которой отправились на поиски приключений после пьянки. В конце своего похождения четверо сильно выпивших мужчин оказались на карусели, которую невозможно остановить. В 2017 году лента «Лалай-Балалай» получила главный приз кинофестиваля «Кинотавр. Короткий метр», стала победителем конкурса короткометражных фильмов «Короче» в Калининграде. По словам режиссера Руслана Братова, фильм основан на реальных событиях. «Я услышал эту историю от друга: как люди зашли на карусель покататься. Дальше она стала обрастать какими-то вещами, которые мы стали придумывать, отталкиваясь от людей, актеров, с которыми я работал. Изначально это история о людях, которые зашли на карусель и катались до победного», — рассказывал он в интервью для телеканала «Культура». «Лалай-Балалай» — дебютная работа Братова. В фильме снялись Евгений Сытый, Алексей Вертков, Павел Ворожцов, Сергей Аброскин и Яна Троянова.\n",
            "5    id=4809\tАкадемия кинематографических искусств и наук опубликовала список фильмов, которые смогут претендовать на премию «Оскар» в категории «Лучший документальный полнометражный фильм». Лонг-лист доступен на сайте американской организации. В список вошли 166 картин, в их числе одна российская — «Дорога» (The Road Movie) режиссера Дмитрия Калашникова. 17 декабря будет объявлен шорт-лист, в который попадут 15 лент из списка. Пять номинантов будут названы 22 января 2019-го, а лауреат «Оскара» станет известен 24 февраля. 10 сентября российский оскаровский комитет выбрал фильм, который поборется за премию американской киноакадемии в номинации «Лучший фильм на иностранном языке». Им стал «Собибор» Константина Хабенского.\n",
            "6    id=5209\tБританский производитель одежды New Look выпустил коллекцию с принтами из кадров культового американского сериала «Друзья». Об этом сообщает Metro. В линейку Friends («Друзья») вошли топы, худи, носки и одежда для сна. На одной из двух представленных черных футболок напечатан фрагмент серии о Дне благодарения с индейкой на голове Моники, а на другой — кадр из «Эпизода с Рождественским Броненосцем» с разодетыми в рождественские костюмы Чендлером и Россом. Обе футболки продаются по цене около 17 долларов. «Друзья» — американский комедийный сериал о жизни шестерых друзей. Проект признан одним из лучших в истории американского телевидения в своем жанре и удостоен шести премий «Эмми» и премии «Золотой глобус». Премьера первой серии состоялась 22 сентября 1994 года. New Look стал не первой маркой, посвятившей коллекцию одежды этому сериалу. В июле в ассортименте испанского масс-маркетового бренда Zara появились вещи с принтами из кадров «Друзей». Одна из них — черная футболка со сценой из той же самой серии, где герои вспоминают свои Дни благодарения.\n",
            "7    id=1452\tНа 48-м году жизни скончался директор Одесской студии мультипликации Юрий Гриневич. Об этом в Facebook сообщила Украинская студия анимационных фильмов. Причина смерти не сообщается. Украинские коллеги художника уточняют, что Гриневич умер внезапно, «за несколько дней». Прощание с мультипликатором состоится 7 декабря в кинозале Одесской киностудии. Среди наиболее заметных работ Гриневича — комедийные телевизионные шоу «Джентльмен-шоу», «Маски-шоу» и «Каламбур», которые транслировались как на Украине, так и по российскому телевидению. Он также снимал анимационные клипы для кабаре-дуэта «Академия» Александра Цекало и Лолиты Милявской.\n",
            "8    id=777\tСамыми разыскиваемыми телешоу в поисковике «Яндекс» за минувший год стали проект «Замуж за Бузову» и «Холостяк» с Егором Кридом. Об этом говорится в итоговом отчете «Яндекса», поступившем в «Ленту.ру». Среди наиболее популярных проектов также оказались «Пацанки», «Битва экстрасенсов» и «Танцы». Кроме того, россияне часто искали выпуски проектов «Песни», «Экстрасенсы. Битва сильнейших», «Мужское/женское», «Прямой эфир», «Взвешенные и счастливые люди». Компания анализировала данные о запросах за период с 1 января по 19 ноября 2018 года. Ранее стало известно, что Первый канал планирует пригласить для участия в новогоднем «Голубом огоньке» российских рэперов. Организатор рэп-дуэлей Versus Battle Александр Тимарцев по прозвищу Ресторатор назвал участие рэперов в новогоднем шоу на центральном канале зашкваром.\n",
            "9    id=1518\tАмериканский институт кинематографии (AFI) опубликовал список десяти лучших сериалов 2018 года. Церемония награждения состоится 4 января 2019 года. В топ-10 вошли такие шоу, как «Американцы», «Убийство Джанни Версаче: Американская история преступлений», «Атланта», «Барри», «Лучше звоните Солу», «Метод Комински», «Удивительная миссис Мейзел», «Поза», «Наследники», «Это мы». Параллельно AFI определил лучшие фильмы 2018-го. В список попали «Звезда родилась», «Черная пантера», «Фаворитка», «Восьмой класс», «Черный клановец» и другие.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7m4YonL7iISP"
      },
      "source": [
        "Теперь оценим качество ранжирования по метрике Recall@k "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3Zx0Bg4iNmX"
      },
      "source": [
        "def get_recall_at_k(targets, predictions, k):\n",
        "    targets_mask = np.repeat(np.expand_dims(targets, 1), k, axis=1)\n",
        "    return (predictions[:, :k] == targets_mask).sum() / len(targets)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0gPC6TOiOiV"
      },
      "source": [
        "test_size = 256\n",
        "test_k = 20"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eK-jYapfiURd"
      },
      "source": [
        "test_requests = random.sample(requests, test_size)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiuoA7MhiVhB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1cf318e-8c23-43d8-c258-396340f2a399"
      },
      "source": [
        "%%time\n",
        "targets = np.zeros(test_size, dtype=np.int32)\n",
        "predictions = np.zeros((test_size, test_k), dtype=np.int32)\n",
        "for i, (request_id, request_text) in enumerate(test_requests):\n",
        "    targets[i] = request_id\n",
        "    predictions[i] = database.find(request_text, k=test_k)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 8.6 s, sys: 6.15 s, total: 14.7 s\n",
            "Wall time: 7.66 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPEfHKhEiWbL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d07e068-0add-47bb-8e2a-41864919e8af"
      },
      "source": [
        "for k in [1, 3, 5, 10, 20]:\n",
        "    print(f'Recall@{k}:\\t{get_recall_at_k(targets, predictions, k):.3f}')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recall@1:\t0.289\n",
            "Recall@3:\t0.473\n",
            "Recall@5:\t0.551\n",
            "Recall@10:\t0.613\n",
            "Recall@20:\t0.719\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWcaqo-_Gt3s"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    }
  ]
}
